{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# æ£€ç´¢ç»„ä»¶ä¼˜åŒ–ä¸è¿›é˜¶æŠ€æœ¯\n",
    "---"
   ],
   "id": "ed82b365035cbbf7"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 1. ç¯å¢ƒå‡†å¤‡\n",
    "- å®‰è£…ä¾èµ–åŒ…\n",
    "- è®¾ç½®é•œåƒæº"
   ],
   "id": "72beb674f6ad25df"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# è®¾ç½®å›½å†…é•œåƒæºï¼ˆåŠ é€Ÿä¸‹è½½ï¼‰\n",
    "import os\n",
    "\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "os.environ[\"HF_ENDPOINT\"] = \"https://hf-mirror.com\"\n",
    "# å®‰è£…ä¾èµ–åŒ…ï¼ˆå–æ¶ˆæ³¨é‡Šè¿è¡Œï¼‰\n",
    "# !pip install langchain faiss-cpu huggingface-hub dashscope PyPDF2"
   ],
   "id": "2d39376021f86bd0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 2. æ–‡æ¡£å¤„ç†\n",
    "- åŠ è½½PDFæ–‡ä»¶\n",
    "- æ£€æŸ¥åŠ è½½ç»“æœ"
   ],
   "id": "50f4f4f4ef79ab61"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "def load_documents(pdf_paths):\n",
    "    \"\"\"åŠ è½½pdfæ–‡æ¡£å¹¶è¿”å›LangChain Documentå¯¹è±¡åˆ—è¡¨\"\"\"\n",
    "    all_docs = []\n",
    "    for path in pdf_paths:\n",
    "        try:\n",
    "            loader = PyPDFLoader(path)\n",
    "            docs = loader.load()\n",
    "            all_docs.extend(docs)\n",
    "            print(f\"æˆåŠŸåŠ è½½ï¼š{path}ï¼ˆå…±{len(docs)}é¡µï¼‰\")\n",
    "        except Exception as e:\n",
    "            print(f\"åŠ è½½å¤±è´¥{path}ï¼š{str(e)}\")\n",
    "    return all_docs\n",
    "\n",
    "# ç¤ºä¾‹ä½¿ç”¨\n",
    "pdf_paths = [\"pdf_China/ä¸­å›½äº§å“è´¨é‡æ³•.pdf\"]\n",
    "processed_documents = load_documents(pdf_paths) # åŸå§‹æ–‡ä»¶\n",
    "print(processed_documents)"
   ],
   "id": "3395d9979278c339",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 3. æ–‡æœ¬åˆ†å‰²ä¸å‘é‡åŒ–\n",
    "\n",
    "- ä¸­æ–‡æ–‡æœ¬åˆ†å‰²"
   ],
   "id": "33662e0603888769"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "def split_documents(docs):\n",
    "    \"\"\"æ‰§è¡Œæ–‡æœ¬åˆ†å‰²\"\"\"\n",
    "    if not docs:\n",
    "        raise ValueError(\"è¾“å…¥æ–‡æ¡£åˆ—è¡¨ä¸ºç©º\")\n",
    "\n",
    "    # ä¸­æ–‡ä¼˜åŒ–åˆ†å‰²å™¨\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=500,     # æ¯ä¸ªæ–‡æœ¬å—500å­—ç¬¦\n",
    "        chunk_overlap=100,  # å—é—´é‡å 100å­—ç¬¦\n",
    "        separators=[\"\\n\\n\", \"\\n\", \"ã€‚\", \"ï¼\", \"ï¼Ÿ\"] # ä¸­æ–‡åˆ†éš”ç¬¦\n",
    "    )\n",
    "\n",
    "    # æ‰§è¡Œåˆ†å‰²\n",
    "    split_docs = text_splitter.split_documents(docs)\n",
    "    print(f\"åˆ†å‰²ä¸º{len(split_docs)}ä¸ªæ–‡æœ¬å—\")\n",
    "\n",
    "    # æŸ¥çœ‹å‰2ä¸ªåˆ†å‰²æ ·ä¾‹\n",
    "    for i, doc in enumerate(split_docs[:2]):\n",
    "        print(f\"\\nå—{i+1}:\\n{doc.page_content[:200]}...\")\n",
    "\n",
    "    return split_docs\n",
    "\n",
    "# ç¤ºä¾‹ä½¿ç”¨\n",
    "split_decs = split_documents(processed_documents)"
   ],
   "id": "2c6e4df9f1971283",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "- æ–‡æœ¬åˆ†å‰²ä¼˜åŒ–",
   "id": "4dce201b23728fed"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# # æ”¹è¿›çš„åˆ†å‰²ç­–ç•¥\n",
    "# from langchain_experimental.text_splitter import SemanticChunker\n",
    "# from langchain.embeddings import OpenAIEmbeddings\n",
    "#\n",
    "# def advanced_text_split(docs):\n",
    "#     embeddings = OpenAIEmbeddings()\n",
    "#     splitter = SemanticChunker(embeddings, breakpoint_threshold_type=\"percentile\")\n",
    "#\n",
    "# # ç¤ºä¾‹ä½¿ç”¨\n",
    "# split_decs2 = advanced_text_split(processed_documents)\n",
    "# print(split_decs2)"
   ],
   "id": "b6b5e069fed7910d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "- æ„å»ºå‘é‡æ•°æ®åº“",
   "id": "76896ea07d19867c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "def create_vector_store(split_docs):\n",
    "    \"\"\"åˆ›å»ºå¹¶è¿”å›å‘é‡æ•°æ®åº“\"\"\"\n",
    "    if not split_docs:\n",
    "        raise ValueError(\"æ— æ³•ç”¨ç©ºæ–‡æ¡£åˆ›å»ºå‘é‡åº“\")\n",
    "\n",
    "    embeddings = HuggingFaceEmbeddings(\n",
    "        model_name=\"distiluse-base-multilingual-cased-v2\"\n",
    "    )\n",
    "\n",
    "    vector_store = FAISS.from_documents(split_docs, embeddings)\n",
    "    print(f\"å‘é‡åº“å·²æ„å»ºï¼ˆåŒ…å«{vector_store.index.ntotal}ï¼‰ä¸ªå‘é‡\")\n",
    "\n",
    "    return vector_store\n",
    "\n",
    "# ç¤ºä¾‹ä½¿ç”¨\n",
    "vector_store = create_vector_store(split_decs)"
   ],
   "id": "5f912b0710bf7a81",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "- æ£€æŸ¥å‘é‡æ•°æ®åº“ä¸­çš„åŸºæœ¬ä¿¡æ¯",
   "id": "ab59e89afa71fcd4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print(f\"å‘é‡æ•°æ®åº“ç±»å‹ï¼š{type(vector_store)}\")\n",
    "\n",
    "print(f\"å‘é‡æ•°æ®åº“ä¸­æ–‡æ¡£æ•°é‡ï¼š{vector_store.index.ntotal}\")\n",
    "\n",
    "print(f\"å‘é‡ç»´åº¦ï¼š{vector_store.index.d}\")"
   ],
   "id": "bca24596fe498df",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 4. åˆ†æå½“å‰æ£€ç´¢ç³»ç»Ÿçš„ç»„æˆ\n",
    "\n",
    "- **å‘é‡æ£€ç´¢**ï¼šç›®å‰ä½¿ç”¨çš„æ˜¯FAISS + HuggingFaceåµŒå…¥æ¨¡å‹(distiluse-base-multilingual-cased-v2)\n",
    "- **æ–‡æœ¬åˆ†å‰²**ï¼šRecursiveCharacterTextSplitterä»¥500å­—ç¬¦ä¸ºå•ä½è¿›è¡Œåˆ†å‰²\n",
    "- **æ£€ç´¢å‚æ•°**ï¼štop-k=3çš„ç›¸ä¼¼åº¦æ£€ç´¢"
   ],
   "id": "ffa8c3af72813e8e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 5. åŸºç¡€å®éªŒä¸æ€§èƒ½è¯„ä¼°",
   "id": "d6e8cc2fffd75b10"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "# æ£€ç´¢åˆ†æå®éªŒ\n",
    "def analyze_retrieval(query, vector_store, top_k=3):\n",
    "    \"\"\"æ·±å…¥åˆ†æå®éªŒç»“æœ\"\"\"\n",
    "    # è·å–åŸå§‹æ£€ç´¢ç»“æœï¼ˆè¿™å¥æ˜¯é›†æˆçš„åŠŸèƒ½ï¼Œä¸‹é¢çš„æ‰æ˜¯å°†å…¶åˆ†å¼€çš„ç»†èŠ‚ï¼‰\n",
    "    docs = vector_store.similarity_search(query, k=top_k)\n",
    "\n",
    "    # è®¡ç®—ç›¸ä¼¼åº¦åˆ†æ•°\n",
    "    embeddings = vector_store.embedding_function # è¿”å›åµŒå…¥æ¨¡å‹å¯¹è±¡ï¼ˆvector_storeæ²¡æœ‰å…¶ä»–ç”¨ï¼‰\n",
    "    query_embedding = embeddings.embed_query(query) # è°ƒç”¨åµŒå…¥æ¨¡å‹å¯¹é—®é¢˜ç¼–ç \n",
    "\n",
    "    print(query_embedding) # è¾“å‡ºé—®é¢˜çš„å‘é‡\n",
    "\n",
    "    print(f\"\\næŸ¥è¯¢ï¼š'{query}'\")\n",
    "    print(f\"æ£€ç´¢åˆ°çš„{len(docs)}ä¸ªæ–‡æ¡£ï¼š\")\n",
    "\n",
    "    for i, doc in enumerate(docs[:top_k]):\n",
    "        doc_embedding = embeddings.embed_query(doc.page_content) # è°ƒç”¨åµŒå…¥æ¨¡å‹å¯¹æ£€ç´¢åˆ°çš„æ–‡æœ¬ç¼–ç \n",
    "        similarity = np.dot(query_embedding, doc_embedding) # è®¡ç®—æŸ¥è¯¢å‘é‡å’Œæ–‡æ¡£å‘é‡ä¹‹é—´çš„ä½™å¼¦ç›¸ä¼¼åº¦\n",
    "        print(f\"\\nğŸ“„ æ–‡æ¡£{i+1} (ç›¸ä¼¼åº¦: {similarity:.4f}):\")\n",
    "        print(f\"  æ¥æº: {doc.metadata.get('source', 'æœªçŸ¥')}\")\n",
    "        print(f\"  å†…å®¹: {doc.page_content[:50]}...\")\n",
    "\n",
    "# ç¤ºä¾‹ä½¿ç”¨\n",
    "queries = [\n",
    "    \"äº§å“è´¨é‡ç›‘ç£æŠ½æŸ¥çš„è§„å®š\",\n",
    "    \"äº§å“ç¼ºé™·çš„æ³•å¾‹å®šä¹‰\",\n",
    "    \"è¿åäº§å“è´¨é‡æ³•çš„å¤„ç½šæªæ–½\"\n",
    "]\n",
    "\n",
    "for query in queries:\n",
    "    analyze_retrieval(query, vector_store)\n"
   ],
   "id": "6b7ae413c75a38e8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 6. æ£€ç´¢è´¨é‡è¯„ä¼°æŒ‡æ ‡\n",
    "\n",
    "**å»ºç«‹ç®€å•çš„è¯„ä¼°ä½“ç³»**ï¼š\n",
    "- å¬å›ç‡(Recall)ï¼šç›¸å…³æ–‡æ¡£è¢«æ£€ç´¢åˆ°çš„æ¯”ä¾‹\n",
    "- å‡†ç¡®ç‡(Precision)ï¼šæ£€ç´¢ç»“æœä¸­ç›¸å…³æ–‡æ¡£çš„æ¯”ä¾‹\n",
    "- å¹³å‡å€’æ•°æ’å(MRR)ï¼šç¬¬ä¸€ä¸ªç›¸å…³æ–‡æ¡£æ’åçš„å€’æ•°"
   ],
   "id": "a2f8258dda728cf0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# ç®€æ˜“è¯„ä¼°æ¡†æ¶\n",
    "def evaluate_retrieval(query, relevant_doc_indices, vector_store, top_k=3):\n",
    "    \"\"\"è¯„ä¼°å•ä¸ªæŸ¥è¯¢çš„æ£€ç´¢ç»“æœ\"\"\"\n",
    "    # æ£€ç´¢åˆ°çš„æ–‡æ¡£ä¿¡æ¯\n",
    "    docs = vector_store.similarity_search(query, k=top_k)\n",
    "    # æå–æ£€ç´¢åˆ°çš„é¡µç \n",
    "    retrieved_indices = [doc.metadata.get('page', -1) for doc in docs]\n",
    "\n",
    "    print(\"docsç±»å‹ï¼š\", type(docs))\n",
    "    # print(docs)\n",
    "\n",
    "    print(\"retrieved_indicesç±»å‹ï¼š\", type(retrieved_indices))\n",
    "    print(\"æ£€ç´¢åˆ°çš„æ–‡æ¡£é¡µç ï¼š\", retrieved_indices)\n",
    "\n",
    "    # è®¡ç®—æŒ‡æ ‡\n",
    "    # æ£€ç´¢åˆ°çš„åˆç›¸å…³çš„ = æ£€ç´¢åˆ°çš„ & ç›¸å…³çš„\n",
    "    relevant_retrieved = len(set(retrieved_indices) & set(relevant_doc_indices))\n",
    "\n",
    "    # å‡†ç¡®ç‡ = æ£€ç´¢åˆ°çš„ç›¸å…³æ–‡æ¡£æ•°/æ£€ç´¢åˆ°çš„æ–‡æ¡£æ€»æ•°\n",
    "    precision = relevant_retrieved / top_k\n",
    "\n",
    "    # å¬å›ç‡ = æ£€ç´¢åˆ°çš„ç›¸å…³æ–‡æ¡£æ•° / æ‰€æœ‰ç›¸å…³æ–‡æ¡£æ•°\n",
    "    recall = relevant_retrieved / len(relevant_doc_indices)\n",
    "\n",
    "    # å¹³å‡å€’æ•°æ’åï¼ˆåœ¨æ£€ç´¢åˆ°çš„æ–‡æ¡£ä¸­ï¼Œç¬¬ä¸€ä¸ªç›¸å…³æ–‡æ¡£æ’åçš„å€’æ•°ï¼‰ï¼ˆçœç•¥äº†å¤šæ¬¡æŸ¥è¯¢æ±‚å¹³å‡çš„æ­¥éª¤ï¼‰\n",
    "    try:\n",
    "        first_relevant_doc = min([i+1 for i, idx in enumerate(retrieved_indices)\n",
    "                                  if idx in relevant_doc_indices])\n",
    "        mrr = 1 / first_relevant_doc\n",
    "    except :\n",
    "        mrr = 0\n",
    "\n",
    "    # è¿”å›ä¸€ä¸ªå­—å…¸\n",
    "    return {\n",
    "        'query': query,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'mrr': mrr\n",
    "    }\n",
    "\n",
    "# ç¤ºä¾‹è¯„ä¼°\n",
    "evaluation_results = []\n",
    "evaluation_results.append(evaluate_retrieval(\n",
    "    \"äº§å“è´¨é‡ç›‘ç£æŠ½æŸ¥çš„è§„å®š\",\n",
    "    [1, 2, 3], # å‡è®¾è¿™äº›é¡µç åŒ…å«ç›¸å…³å†…å®¹\n",
    "    vector_store\n",
    "))\n",
    "print(evaluation_results)"
   ],
   "id": "36370bf0675e477",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
