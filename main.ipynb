{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# RAGé€šç”¨é—®ç­”ç³»ç»Ÿ\n",
    "---"
   ],
   "id": "ed82b365035cbbf7"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 1. ç¯å¢ƒå‡†å¤‡\n",
    "- å®‰è£…ä¾èµ–åŒ…\n",
    "- è®¾ç½®é•œåƒæº"
   ],
   "id": "72beb674f6ad25df"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# è®¾ç½®å›½å†…é•œåƒæºï¼ˆåŠ é€Ÿä¸‹è½½ï¼‰\n",
    "import os\n",
    "\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "os.environ[\"HF_ENDPOINT\"] = \"https://hf-mirror.com\"\n",
    "# å®‰è£…ä¾èµ–åŒ…ï¼ˆå–æ¶ˆæ³¨é‡Šè¿è¡Œï¼‰\n",
    "# !pip install langchain faiss-cpu huggingface-hub dashscope PyPDF2"
   ],
   "id": "2d39376021f86bd0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 2. æ–‡æ¡£å¤„ç†\n",
    "- åŠ è½½PDFæ–‡ä»¶\n",
    "- æ£€æŸ¥åŠ è½½ç»“æœ"
   ],
   "id": "50f4f4f4ef79ab61"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "def load_documents(pdf_paths):\n",
    "    \"\"\"åŠ è½½pdfæ–‡æ¡£å¹¶è¿”å›LangChain Documentå¯¹è±¡åˆ—è¡¨\"\"\"\n",
    "    all_docs = []\n",
    "    for path in pdf_paths:\n",
    "        try:\n",
    "            loader = PyPDFLoader(path)\n",
    "            docs = loader.load()\n",
    "            all_docs.extend(docs)\n",
    "            print(f\"æˆåŠŸåŠ è½½ï¼š{path}ï¼ˆå…±{len(docs)}é¡µï¼‰\")\n",
    "        except Exception as e:\n",
    "            print(f\"åŠ è½½å¤±è´¥{path}ï¼š{str(e)}\")\n",
    "    return all_docs\n",
    "\n",
    "# ç¤ºä¾‹ä½¿ç”¨\n",
    "pdf_paths = [\"pdf_China/ä¸­å›½äº§å“è´¨é‡æ³•.pdf\"]\n",
    "processed_documents = load_documents(pdf_paths) # åŸå§‹æ–‡ä»¶\n",
    "print(processed_documents)"
   ],
   "id": "3395d9979278c339",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 3. æ–‡æœ¬åˆ†å‰²ä¸å‘é‡åŒ–\n",
    "- ä¸­æ–‡æ–‡æœ¬åˆ†å‰²\n",
    "- æ„å»ºå‘é‡æ•°æ®åº“"
   ],
   "id": "33662e0603888769"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "def split_documents(docs):\n",
    "    \"\"\"æ‰§è¡Œæ–‡æœ¬åˆ†å‰²\"\"\"\n",
    "    if not docs:\n",
    "        raise ValueError(\"è¾“å…¥æ–‡æ¡£åˆ—è¡¨ä¸ºç©º\")\n",
    "\n",
    "    # ä¸­æ–‡ä¼˜åŒ–åˆ†å‰²å™¨\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=500,     # æ¯ä¸ªæ–‡æœ¬å—500å­—ç¬¦\n",
    "        chunk_overlap=100,  # å—é—´é‡å 100å­—ç¬¦\n",
    "        separators=[\"\\n\\n\", \"\\n\", \"ã€‚\", \"ï¼\", \"ï¼Ÿ\"] # ä¸­æ–‡åˆ†éš”ç¬¦\n",
    "    )\n",
    "\n",
    "    # æ‰§è¡Œåˆ†å‰²\n",
    "    split_docs = text_splitter.split_documents(docs)\n",
    "    print(f\"åˆ†å‰²ä¸º{len(split_docs)}ä¸ªæ–‡æœ¬å—\")\n",
    "\n",
    "    # æŸ¥çœ‹å‰2ä¸ªåˆ†å‰²æ ·ä¾‹\n",
    "    for i, doc in enumerate(split_docs[:2]):\n",
    "        print(f\"\\nå—{i+1}:\\n{doc.page_content[:200]}...\")\n",
    "\n",
    "    return split_docs\n",
    "\n",
    "# ç¤ºä¾‹ä½¿ç”¨\n",
    "split_decs = split_documents(processed_documents)"
   ],
   "id": "2c6e4df9f1971283",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "def create_vector_store(split_docs):\n",
    "    \"\"\"åˆ›å»ºå¹¶è¿”å›å‘é‡æ•°æ®åº“\"\"\"\n",
    "    if not split_docs:\n",
    "        raise ValueError(\"æ— æ³•ç”¨ç©ºæ–‡æ¡£åˆ›å»ºå‘é‡åº“\")\n",
    "\n",
    "    embeddings = HuggingFaceEmbeddings(\n",
    "        model_name=\"distiluse-base-multilingual-cased-v2\"\n",
    "    )\n",
    "\n",
    "    vector_store = FAISS.from_documents(split_docs, embeddings)\n",
    "    print(f\"å‘é‡åº“å·²æ„å»ºï¼ˆåŒ…å«{vector_store.index.ntotal}ï¼‰ä¸ªå‘é‡\")\n",
    "\n",
    "    return vector_store\n",
    "\n",
    "# ç¤ºä¾‹ä½¿ç”¨\n",
    "vector_store = create_vector_store(split_decs)"
   ],
   "id": "5f912b0710bf7a81",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 4. é€šä¹‰åƒé—®é…ç½®\n",
    "- è®¾ç½®APIå¯†é’¥\n",
    "- åˆå§‹åŒ–æ¨¡å‹å‚æ•°"
   ],
   "id": "44bc3b4632a030d6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from langchain_community.llms import Tongyi\n",
    "# import dashscope\n",
    "\n",
    "# dashscope.api_key = \"ä¿å¯†\"\n",
    "qwen_llm = Tongyi(model_name=\"qwen-turbo\", temperature=0.3) # ä½¿ç”¨é€šä¹‰åƒé—®çš„-turboæ¨¡å‹ï¼Œè°ƒæ•´æ¨¡å‹ç¨³å®šåº¦ä¸º0.3"
   ],
   "id": "9629293cf805b97e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "\n",
    "## 5. RAGæ ¸å¿ƒé“¾\n",
    "- è®¾è®¡æç¤ºæ¨¡æ¿\n",
    "- ç»„åˆæ£€ç´¢ä¸ç”Ÿæˆæ¨¡å—"
   ],
   "id": "2909535f115990f0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "def get_answer(question:str, vs, llm):\n",
    "    \"\"\"ä¼ ç»Ÿå‡½æ•°è¯•å®ç°ï¼ˆä¸RAGé“¾åŒºåˆ†ï¼‰\"\"\"\n",
    "    # å°†å‘é‡åº“è½¬æ¢ä¸ºæ£€ç´¢å™¨ï¼ˆå…·å¤‡æ£€ç´¢åŠŸèƒ½ï¼‰\n",
    "    retriever = vs.as_retriever(search_kwargs={\"k\":3})\n",
    "\n",
    "    # æ‰§è¡Œæ£€ç´¢\n",
    "    retrieve_docs = retriever.invoke(question)\n",
    "\n",
    "    # æ„å»ºæç¤ºè¯æ¨¡æ¿\n",
    "    prompt = ChatPromptTemplate.from_template(\n",
    "        \"\"\"ä½ æ˜¯ä¸€ä¸ªä¸“å®¶ï¼Œè¯·æ ¹æ®ä¸Šä¸‹æ–‡å›ç­”é—®é¢˜ï¼š\n",
    "        ä¸Šä¸‹æ–‡ï¼š{context}\n",
    "        é—®é¢˜ï¼š{question}\n",
    "        ä¸“ä¸šå›ç­”ï¼š\"\"\"\n",
    "    )\n",
    "\n",
    "    # å¡«å……æç¤ºè¯æ¨¡æ¿\n",
    "    formatted_prompt = prompt.format_messages(\n",
    "        context=retrieve_docs,\n",
    "        question=question\n",
    "    )\n",
    "\n",
    "    # è°ƒç”¨LLM\n",
    "    llm_response = llm.invoke(formatted_prompt)\n",
    "\n",
    "    # è§£æè¾“å‡º\n",
    "    return StrOutputParser().invoke(llm_response)\n",
    "\n",
    "# ä½¿ç”¨ç¤ºä¾‹\n",
    "answer = get_answer(\"ä¸­å›½äº§å“è´¨é‡æ³•ç¬¬ä¸€æ¡æ˜¯ä»€ä¹ˆï¼Ÿ\", vector_store, qwen_llm)\n",
    "print(answer)"
   ],
   "id": "e7a3fa20fdbdaa00",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 6. äº¤äº’æµ‹è¯•\n",
    "- å®ç°é—®ç­”å¾ªç¯\n",
    "- é€€å‡ºæœºåˆ¶"
   ],
   "id": "a1b78fdb414662f4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def interactive_qa_test(vector_store, llm):\n",
    "    \"\"\"\n",
    "    ä¼ ç»Ÿå‡½æ•°å¼äº¤äº’æµ‹è¯•\n",
    "    å‚æ•°:\n",
    "        vector_store: å·²åˆ›å»ºçš„å‘é‡æ•°æ®åº“å¯¹è±¡\n",
    "        llm: å·²åˆå§‹åŒ–çš„è¯­è¨€æ¨¡å‹\n",
    "    \"\"\"\n",
    "    print(\"\"\"\\nğŸŸ¢ æ³•å¾‹é—®ç­”ç³»ç»Ÿ(ä¼ ç»Ÿå¼)å·²å¯åŠ¨\n",
    "    ----------------------------------\n",
    "    ä½¿ç”¨è¯´æ˜:\n",
    "    1. è¾“å…¥é—®é¢˜è·å–æ³•å¾‹æ¡æ–‡è§£ç­”\n",
    "    2. è¾“å…¥ä»¥ä¸‹å‘½ä»¤å¯æ‰§è¡Œæ“ä½œ:\n",
    "       /quit  - é€€å‡ºç³»ç»Ÿ\n",
    "    ----------------------------------\"\"\")\n",
    "\n",
    "    while True:\n",
    "        try:\n",
    "            # è·å–ç”¨æˆ·è¾“å…¥\n",
    "            user_input = input(\"\\nâ“ è¯·è¾“å…¥é—®é¢˜æˆ–å‘½ä»¤: \").strip()\n",
    "\n",
    "            if not user_input:\n",
    "                print(\"âš ï¸ è¾“å…¥ä¸èƒ½ä¸ºç©ºï¼Œè¯·é‡æ–°è¾“å…¥\")\n",
    "                continue\n",
    "\n",
    "            # å¤„ç†é€€å‡ºå‘½ä»¤\n",
    "            if user_input.lower() in ['/quit', '/exit', '/q']:\n",
    "                print(\"ğŸ›‘ ç³»ç»Ÿå·²é€€å‡º\")\n",
    "                break\n",
    "\n",
    "            # æ‰§è¡Œé—®ç­”æµç¨‹\n",
    "            print(\"\\nğŸ” æ­£åœ¨å¤„ç†é—®é¢˜...\")\n",
    "            answer = get_answer(user_input, vector_store, llm)\n",
    "\n",
    "            # æ˜¾ç¤ºç»“æœ\n",
    "            print(f\"\\nğŸ’¡ ç­”æ¡ˆ: {answer}\")\n",
    "            print(\"-\" * 50)  # åˆ†éš”çº¿\n",
    "\n",
    "        except KeyboardInterrupt:\n",
    "            print(\"\\nğŸ›‘ ç”¨æˆ·ä¸­æ–­æ“ä½œ\")\n",
    "            break\n",
    "        except Exception as e:\n",
    "            print(f\"\\nâŒ å‘ç”Ÿé”™è¯¯: {str(e)}\")\n",
    "\n",
    "# ===== ä½¿ç”¨ç¤ºä¾‹ =====\n",
    "# åœ¨Notebookæœ«å°¾å•å…ƒæ ¼è°ƒç”¨ï¼ˆéœ€å…ˆåˆå§‹åŒ–vector_storeå’Œqwen_llmï¼‰\n",
    "if __name__ == \"__main__\":\n",
    "    interactive_qa_test(vector_store, qwen_llm)"
   ],
   "id": "35167a90973435e3",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
