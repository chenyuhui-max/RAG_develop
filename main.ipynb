{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# RAG通用问答系统\n",
    "---"
   ],
   "id": "ed82b365035cbbf7"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 1. 环境准备\n",
    "- 安装依赖包\n",
    "- 设置镜像源"
   ],
   "id": "72beb674f6ad25df"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 设置国内镜像源（加速下载）\n",
    "import os\n",
    "\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "os.environ[\"HF_ENDPOINT\"] = \"https://hf-mirror.com\"\n",
    "# 安装依赖包（取消注释运行）\n",
    "# !pip install langchain faiss-cpu huggingface-hub dashscope PyPDF2"
   ],
   "id": "2d39376021f86bd0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 2. 文档处理\n",
    "- 加载PDF文件\n",
    "- 检查加载结果"
   ],
   "id": "50f4f4f4ef79ab61"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "def load_documents(pdf_paths):\n",
    "    \"\"\"加载pdf文档并返回LangChain Document对象列表\"\"\"\n",
    "    all_docs = []\n",
    "    for path in pdf_paths:\n",
    "        try:\n",
    "            loader = PyPDFLoader(path)\n",
    "            docs = loader.load()\n",
    "            all_docs.extend(docs)\n",
    "            print(f\"成功加载：{path}（共{len(docs)}页）\")\n",
    "        except Exception as e:\n",
    "            print(f\"加载失败{path}：{str(e)}\")\n",
    "    return all_docs\n",
    "\n",
    "# 示例使用\n",
    "pdf_paths = [\"pdf_China/中国产品质量法.pdf\"]\n",
    "processed_documents = load_documents(pdf_paths) # 原始文件\n",
    "print(processed_documents)"
   ],
   "id": "3395d9979278c339",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 3. 文本分割与向量化\n",
    "- 中文文本分割\n",
    "- 构建向量数据库"
   ],
   "id": "33662e0603888769"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "def split_documents(docs):\n",
    "    \"\"\"执行文本分割\"\"\"\n",
    "    if not docs:\n",
    "        raise ValueError(\"输入文档列表为空\")\n",
    "\n",
    "    # 中文优化分割器\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=500,     # 每个文本块500字符\n",
    "        chunk_overlap=100,  # 块间重叠100字符\n",
    "        separators=[\"\\n\\n\", \"\\n\", \"。\", \"！\", \"？\"] # 中文分隔符\n",
    "    )\n",
    "\n",
    "    # 执行分割\n",
    "    split_docs = text_splitter.split_documents(docs)\n",
    "    print(f\"分割为{len(split_docs)}个文本块\")\n",
    "\n",
    "    # 查看前2个分割样例\n",
    "    for i, doc in enumerate(split_docs[:2]):\n",
    "        print(f\"\\n块{i+1}:\\n{doc.page_content[:200]}...\")\n",
    "\n",
    "    return split_docs\n",
    "\n",
    "# 示例使用\n",
    "split_decs = split_documents(processed_documents)"
   ],
   "id": "2c6e4df9f1971283",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "def create_vector_store(split_docs):\n",
    "    \"\"\"创建并返回向量数据库\"\"\"\n",
    "    if not split_docs:\n",
    "        raise ValueError(\"无法用空文档创建向量库\")\n",
    "\n",
    "    embeddings = HuggingFaceEmbeddings(\n",
    "        model_name=\"distiluse-base-multilingual-cased-v2\"\n",
    "    )\n",
    "\n",
    "    vector_store = FAISS.from_documents(split_docs, embeddings)\n",
    "    print(f\"向量库已构建（包含{vector_store.index.ntotal}）个向量\")\n",
    "\n",
    "    return vector_store\n",
    "\n",
    "# 示例使用\n",
    "vector_store = create_vector_store(split_decs)"
   ],
   "id": "5f912b0710bf7a81",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 4. 通义千问配置\n",
    "- 设置API密钥\n",
    "- 初始化模型参数"
   ],
   "id": "44bc3b4632a030d6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from langchain_community.llms import Tongyi\n",
    "# import dashscope\n",
    "\n",
    "# dashscope.api_key = \"保密\"\n",
    "qwen_llm = Tongyi(model_name=\"qwen-turbo\", temperature=0.3) # 使用通义千问的-turbo模型，调整模型稳定度为0.3"
   ],
   "id": "9629293cf805b97e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "\n",
    "## 5. RAG核心链\n",
    "- 设计提示模板\n",
    "- 组合检索与生成模块"
   ],
   "id": "2909535f115990f0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "def get_answer(question:str, vs, llm):\n",
    "    \"\"\"传统函数试实现（与RAG链区分）\"\"\"\n",
    "    # 将向量库转换为检索器（具备检索功能）\n",
    "    retriever = vs.as_retriever(search_kwargs={\"k\":3})\n",
    "\n",
    "    # 执行检索\n",
    "    retrieve_docs = retriever.invoke(question)\n",
    "\n",
    "    # 构建提示词模板\n",
    "    prompt = ChatPromptTemplate.from_template(\n",
    "        \"\"\"你是一个专家，请根据上下文回答问题：\n",
    "        上下文：{context}\n",
    "        问题：{question}\n",
    "        专业回答：\"\"\"\n",
    "    )\n",
    "\n",
    "    # 填充提示词模板\n",
    "    formatted_prompt = prompt.format_messages(\n",
    "        context=retrieve_docs,\n",
    "        question=question\n",
    "    )\n",
    "\n",
    "    # 调用LLM\n",
    "    llm_response = llm.invoke(formatted_prompt)\n",
    "\n",
    "    # 解析输出\n",
    "    return StrOutputParser().invoke(llm_response)\n",
    "\n",
    "# 使用示例\n",
    "answer = get_answer(\"中国产品质量法第一条是什么？\", vector_store, qwen_llm)\n",
    "print(answer)"
   ],
   "id": "e7a3fa20fdbdaa00",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 6. 交互测试\n",
    "- 实现问答循环\n",
    "- 退出机制"
   ],
   "id": "a1b78fdb414662f4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def interactive_qa_test(vector_store, llm):\n",
    "    \"\"\"\n",
    "    传统函数式交互测试\n",
    "    参数:\n",
    "        vector_store: 已创建的向量数据库对象\n",
    "        llm: 已初始化的语言模型\n",
    "    \"\"\"\n",
    "    print(\"\"\"\\n🟢 法律问答系统(传统式)已启动\n",
    "    ----------------------------------\n",
    "    使用说明:\n",
    "    1. 输入问题获取法律条文解答\n",
    "    2. 输入以下命令可执行操作:\n",
    "       /quit  - 退出系统\n",
    "    ----------------------------------\"\"\")\n",
    "\n",
    "    while True:\n",
    "        try:\n",
    "            # 获取用户输入\n",
    "            user_input = input(\"\\n❓ 请输入问题或命令: \").strip()\n",
    "\n",
    "            if not user_input:\n",
    "                print(\"⚠️ 输入不能为空，请重新输入\")\n",
    "                continue\n",
    "\n",
    "            # 处理退出命令\n",
    "            if user_input.lower() in ['/quit', '/exit', '/q']:\n",
    "                print(\"🛑 系统已退出\")\n",
    "                break\n",
    "\n",
    "            # 执行问答流程\n",
    "            print(\"\\n🔍 正在处理问题...\")\n",
    "            answer = get_answer(user_input, vector_store, llm)\n",
    "\n",
    "            # 显示结果\n",
    "            print(f\"\\n💡 答案: {answer}\")\n",
    "            print(\"-\" * 50)  # 分隔线\n",
    "\n",
    "        except KeyboardInterrupt:\n",
    "            print(\"\\n🛑 用户中断操作\")\n",
    "            break\n",
    "        except Exception as e:\n",
    "            print(f\"\\n❌ 发生错误: {str(e)}\")\n",
    "\n",
    "# ===== 使用示例 =====\n",
    "# 在Notebook末尾单元格调用（需先初始化vector_store和qwen_llm）\n",
    "if __name__ == \"__main__\":\n",
    "    interactive_qa_test(vector_store, qwen_llm)"
   ],
   "id": "35167a90973435e3",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
